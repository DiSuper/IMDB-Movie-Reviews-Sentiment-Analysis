{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 95.476% acc **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/word2vec-nlp-tutorial/sampleSubmission.csv\n",
      "/kaggle/input/word2vec-nlp-tutorial/unlabeledTrainData.tsv\n",
      "/kaggle/input/word2vec-nlp-tutorial/testData.tsv\n",
      "/kaggle/input/word2vec-nlp-tutorial/labeledTrainData.tsv\n",
      "/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:10: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(75000, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd       \n",
    "train0 = pd.read_csv(\"/kaggle/input/word2vec-nlp-tutorial/labeledTrainData.tsv\", header=0, \\\n",
    "                    delimiter=\"\\t\", quoting=3)\n",
    "test = pd.read_csv(\"/kaggle/input/word2vec-nlp-tutorial/testData.tsv\", header=0, delimiter=\"\\t\", \\\n",
    "                   quoting=3 )\n",
    "train1=pd.read_csv(\"../input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\")\n",
    "train1['sentiment'] = train1['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "train0=train0.drop('id',axis=1)\n",
    "train= pd.concat([train0, train1]).reset_index(drop=True)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('all')  # Download text data sets, including stop words\n",
    "from nltk.corpus import stopwords # Import the stop word list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup             \n",
    "import re\n",
    "def review_to_words( raw_review ):\n",
    "    # Function to convert a raw review to a string of words\n",
    "    # The input is a single string (a raw movie review), and \n",
    "    # the output is a single string (a preprocessed movie review)\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(raw_review).get_text() \n",
    "    #\n",
    "    # 2. Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text) \n",
    "    #\n",
    "    # 3. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()                             \n",
    "    #\n",
    "    # 4. In Python, searching a set is much faster than searching\n",
    "    #   a list, so convert the stop words to a set\n",
    "    stops = set(stopwords.words(\"english\"))                  \n",
    "    # \n",
    "    # 5. Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]   \n",
    "    #\n",
    "    # 6. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return( \" \".join( meaningful_words ))  \n",
    "\n",
    "\n",
    "# Initialize the BeautifulSoup object on a single movie review     \n",
    "cleaned_reviews=[]\n",
    "for review in train[\"review\"]:\n",
    "    cleaned_reviews.append(review_to_words( review ))\n",
    "\n",
    "all_text = ' '.join(cleaned_reviews)\n",
    "words = all_text.split()\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "counts = Counter(words)\n",
    "vocab = sorted(counts, key=counts.get, reverse=True)\n",
    "vocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}\n",
    "\n",
    "reviews_ints = []\n",
    "for each in cleaned_reviews:\n",
    "    reviews_ints.append([vocab_to_int[word] for word in each.split()])\n",
    "\n",
    "\n",
    "\n",
    "labels = np.array(train['sentiment'])\n",
    "\n",
    "non_zero_idx = [ii for ii, review in enumerate(reviews_ints) if len(review) != 0]\n",
    "reviews_ints = [reviews_ints[ii] for ii in non_zero_idx]\n",
    "labels = np.array([labels[ii] for ii in non_zero_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tFeature Shapes:\n",
      "Train set: \t\t(60000, 1000) \n",
      "Validation set: \t(7500, 1000) \n",
      "Test set: \t\t(7500, 1000)\n",
      "Epoch: 0/10 Iteration: 5 Train loss: 0.245\n",
      "Epoch: 0/10 Iteration: 10 Train loss: 0.223\n",
      "Epoch: 0/10 Iteration: 15 Train loss: 0.196\n",
      "Epoch: 0/10 Iteration: 20 Train loss: 0.179\n",
      "Epoch: 0/10 Iteration: 25 Train loss: 0.188\n",
      "Val acc: 0.757\n",
      "Epoch: 0/10 Iteration: 30 Train loss: 0.171\n",
      "Epoch: 0/10 Iteration: 35 Train loss: 0.138\n",
      "Epoch: 0/10 Iteration: 40 Train loss: 0.129\n",
      "Epoch: 0/10 Iteration: 45 Train loss: 0.143\n",
      "Epoch: 0/10 Iteration: 50 Train loss: 0.126\n",
      "Val acc: 0.838\n",
      "Epoch: 0/10 Iteration: 55 Train loss: 0.128\n",
      "Epoch: 0/10 Iteration: 60 Train loss: 0.117\n",
      "Epoch: 0/10 Iteration: 65 Train loss: 0.096\n",
      "Epoch: 0/10 Iteration: 70 Train loss: 0.093\n",
      "Epoch: 0/10 Iteration: 75 Train loss: 0.109\n",
      "Val acc: 0.855\n",
      "Epoch: 0/10 Iteration: 80 Train loss: 0.092\n",
      "Epoch: 0/10 Iteration: 85 Train loss: 0.112\n",
      "Epoch: 0/10 Iteration: 90 Train loss: 0.100\n",
      "Epoch: 0/10 Iteration: 95 Train loss: 0.111\n",
      "Epoch: 0/10 Iteration: 100 Train loss: 0.103\n",
      "Val acc: 0.860\n",
      "Epoch: 0/10 Iteration: 105 Train loss: 0.105\n",
      "Epoch: 0/10 Iteration: 110 Train loss: 0.094\n",
      "Epoch: 0/10 Iteration: 115 Train loss: 0.111\n",
      "Epoch: 0/10 Iteration: 120 Train loss: 0.109\n",
      "Epoch: 1/10 Iteration: 125 Train loss: 0.071\n",
      "Val acc: 0.878\n",
      "Epoch: 1/10 Iteration: 130 Train loss: 0.071\n",
      "Epoch: 1/10 Iteration: 135 Train loss: 0.083\n",
      "Epoch: 1/10 Iteration: 140 Train loss: 0.082\n",
      "Epoch: 1/10 Iteration: 145 Train loss: 0.111\n",
      "Epoch: 1/10 Iteration: 150 Train loss: 0.084\n",
      "Val acc: 0.885\n",
      "Epoch: 1/10 Iteration: 155 Train loss: 0.070\n",
      "Epoch: 1/10 Iteration: 160 Train loss: 0.079\n",
      "Epoch: 1/10 Iteration: 165 Train loss: 0.071\n",
      "Epoch: 1/10 Iteration: 170 Train loss: 0.055\n",
      "Epoch: 1/10 Iteration: 175 Train loss: 0.066\n",
      "Val acc: 0.900\n",
      "Epoch: 1/10 Iteration: 180 Train loss: 0.064\n",
      "Epoch: 1/10 Iteration: 185 Train loss: 0.044\n",
      "Epoch: 1/10 Iteration: 190 Train loss: 0.038\n",
      "Epoch: 1/10 Iteration: 195 Train loss: 0.052\n",
      "Epoch: 1/10 Iteration: 200 Train loss: 0.048\n",
      "Val acc: 0.897\n",
      "Epoch: 1/10 Iteration: 205 Train loss: 0.068\n",
      "Epoch: 1/10 Iteration: 210 Train loss: 0.059\n",
      "Epoch: 1/10 Iteration: 215 Train loss: 0.063\n",
      "Epoch: 1/10 Iteration: 220 Train loss: 0.063\n",
      "Epoch: 1/10 Iteration: 225 Train loss: 0.053\n",
      "Val acc: 0.899\n",
      "Epoch: 1/10 Iteration: 230 Train loss: 0.060\n",
      "Epoch: 1/10 Iteration: 235 Train loss: 0.079\n",
      "Epoch: 1/10 Iteration: 240 Train loss: 0.075\n",
      "Epoch: 2/10 Iteration: 245 Train loss: 0.056\n",
      "Epoch: 2/10 Iteration: 250 Train loss: 0.042\n",
      "Val acc: 0.904\n",
      "Epoch: 2/10 Iteration: 255 Train loss: 0.052\n",
      "Epoch: 2/10 Iteration: 260 Train loss: 0.055\n",
      "Epoch: 2/10 Iteration: 265 Train loss: 0.053\n",
      "Epoch: 2/10 Iteration: 270 Train loss: 0.060\n",
      "Epoch: 2/10 Iteration: 275 Train loss: 0.038\n",
      "Val acc: 0.912\n",
      "Epoch: 2/10 Iteration: 280 Train loss: 0.038\n",
      "Epoch: 2/10 Iteration: 285 Train loss: 0.046\n",
      "Epoch: 2/10 Iteration: 290 Train loss: 0.040\n",
      "Epoch: 2/10 Iteration: 295 Train loss: 0.048\n",
      "Epoch: 2/10 Iteration: 300 Train loss: 0.046\n",
      "Val acc: 0.913\n",
      "Epoch: 2/10 Iteration: 305 Train loss: 0.024\n",
      "Epoch: 2/10 Iteration: 310 Train loss: 0.027\n",
      "Epoch: 2/10 Iteration: 315 Train loss: 0.033\n",
      "Epoch: 2/10 Iteration: 320 Train loss: 0.033\n",
      "Epoch: 2/10 Iteration: 325 Train loss: 0.039\n",
      "Val acc: 0.909\n",
      "Epoch: 2/10 Iteration: 330 Train loss: 0.033\n",
      "Epoch: 2/10 Iteration: 335 Train loss: 0.041\n",
      "Epoch: 2/10 Iteration: 340 Train loss: 0.035\n",
      "Epoch: 2/10 Iteration: 345 Train loss: 0.033\n",
      "Epoch: 2/10 Iteration: 350 Train loss: 0.034\n",
      "Val acc: 0.905\n",
      "Epoch: 2/10 Iteration: 355 Train loss: 0.040\n",
      "Epoch: 2/10 Iteration: 360 Train loss: 0.057\n",
      "Epoch: 3/10 Iteration: 365 Train loss: 0.037\n",
      "Epoch: 3/10 Iteration: 370 Train loss: 0.035\n",
      "Epoch: 3/10 Iteration: 375 Train loss: 0.035\n",
      "Val acc: 0.893\n",
      "Epoch: 3/10 Iteration: 380 Train loss: 0.053\n",
      "Epoch: 3/10 Iteration: 385 Train loss: 0.049\n",
      "Epoch: 3/10 Iteration: 390 Train loss: 0.048\n",
      "Epoch: 3/10 Iteration: 395 Train loss: 0.036\n",
      "Epoch: 3/10 Iteration: 400 Train loss: 0.025\n",
      "Val acc: 0.913\n",
      "Epoch: 3/10 Iteration: 405 Train loss: 0.040\n",
      "Epoch: 3/10 Iteration: 410 Train loss: 0.024\n",
      "Epoch: 3/10 Iteration: 415 Train loss: 0.041\n",
      "Epoch: 3/10 Iteration: 420 Train loss: 0.042\n",
      "Epoch: 3/10 Iteration: 425 Train loss: 0.024\n",
      "Val acc: 0.915\n",
      "Epoch: 3/10 Iteration: 430 Train loss: 0.021\n",
      "Epoch: 3/10 Iteration: 435 Train loss: 0.032\n",
      "Epoch: 3/10 Iteration: 440 Train loss: 0.028\n",
      "Epoch: 3/10 Iteration: 445 Train loss: 0.042\n",
      "Epoch: 3/10 Iteration: 450 Train loss: 0.026\n",
      "Val acc: 0.917\n",
      "Epoch: 3/10 Iteration: 455 Train loss: 0.032\n",
      "Epoch: 3/10 Iteration: 460 Train loss: 0.030\n",
      "Epoch: 3/10 Iteration: 465 Train loss: 0.028\n",
      "Epoch: 3/10 Iteration: 470 Train loss: 0.028\n",
      "Epoch: 3/10 Iteration: 475 Train loss: 0.037\n",
      "Val acc: 0.913\n",
      "Epoch: 3/10 Iteration: 480 Train loss: 0.044\n",
      "Epoch: 4/10 Iteration: 485 Train loss: 0.022\n",
      "Epoch: 4/10 Iteration: 490 Train loss: 0.025\n",
      "Epoch: 4/10 Iteration: 495 Train loss: 0.027\n",
      "Epoch: 4/10 Iteration: 500 Train loss: 0.030\n",
      "Val acc: 0.915\n",
      "Epoch: 4/10 Iteration: 505 Train loss: 0.034\n",
      "Epoch: 4/10 Iteration: 510 Train loss: 0.026\n",
      "Epoch: 4/10 Iteration: 515 Train loss: 0.018\n",
      "Epoch: 4/10 Iteration: 520 Train loss: 0.017\n",
      "Epoch: 4/10 Iteration: 525 Train loss: 0.021\n",
      "Val acc: 0.925\n",
      "Epoch: 4/10 Iteration: 530 Train loss: 0.015\n",
      "Epoch: 4/10 Iteration: 535 Train loss: 0.024\n",
      "Epoch: 4/10 Iteration: 540 Train loss: 0.028\n",
      "Epoch: 4/10 Iteration: 545 Train loss: 0.011\n",
      "Epoch: 4/10 Iteration: 550 Train loss: 0.016\n",
      "Val acc: 0.923\n",
      "Epoch: 4/10 Iteration: 555 Train loss: 0.015\n",
      "Epoch: 4/10 Iteration: 560 Train loss: 0.025\n",
      "Epoch: 4/10 Iteration: 565 Train loss: 0.029\n",
      "Epoch: 4/10 Iteration: 570 Train loss: 0.019\n",
      "Epoch: 4/10 Iteration: 575 Train loss: 0.029\n",
      "Val acc: 0.921\n",
      "Epoch: 4/10 Iteration: 580 Train loss: 0.026\n",
      "Epoch: 4/10 Iteration: 585 Train loss: 0.020\n",
      "Epoch: 4/10 Iteration: 590 Train loss: 0.020\n",
      "Epoch: 4/10 Iteration: 595 Train loss: 0.039\n",
      "Epoch: 4/10 Iteration: 600 Train loss: 0.037\n",
      "Val acc: 0.921\n",
      "Epoch: 5/10 Iteration: 605 Train loss: 0.022\n",
      "Epoch: 5/10 Iteration: 610 Train loss: 0.015\n",
      "Epoch: 5/10 Iteration: 615 Train loss: 0.020\n",
      "Epoch: 5/10 Iteration: 620 Train loss: 0.025\n",
      "Epoch: 5/10 Iteration: 625 Train loss: 0.018\n",
      "Val acc: 0.924\n",
      "Epoch: 5/10 Iteration: 630 Train loss: 0.013\n",
      "Epoch: 5/10 Iteration: 635 Train loss: 0.019\n",
      "Epoch: 5/10 Iteration: 640 Train loss: 0.018\n",
      "Epoch: 5/10 Iteration: 645 Train loss: 0.014\n",
      "Epoch: 5/10 Iteration: 650 Train loss: 0.013\n",
      "Val acc: 0.926\n",
      "Epoch: 5/10 Iteration: 655 Train loss: 0.018\n",
      "Epoch: 5/10 Iteration: 660 Train loss: 0.024\n",
      "Epoch: 5/10 Iteration: 665 Train loss: 0.010\n",
      "Epoch: 5/10 Iteration: 670 Train loss: 0.009\n",
      "Epoch: 5/10 Iteration: 675 Train loss: 0.020\n",
      "Val acc: 0.917\n",
      "Epoch: 5/10 Iteration: 680 Train loss: 0.020\n",
      "Epoch: 5/10 Iteration: 685 Train loss: 0.038\n",
      "Epoch: 5/10 Iteration: 690 Train loss: 0.021\n",
      "Epoch: 5/10 Iteration: 695 Train loss: 0.025\n",
      "Epoch: 5/10 Iteration: 700 Train loss: 0.020\n",
      "Val acc: 0.922\n",
      "Epoch: 5/10 Iteration: 705 Train loss: 0.021\n",
      "Epoch: 5/10 Iteration: 710 Train loss: 0.015\n",
      "Epoch: 5/10 Iteration: 715 Train loss: 0.012\n",
      "Epoch: 5/10 Iteration: 720 Train loss: 0.028\n",
      "Epoch: 6/10 Iteration: 725 Train loss: 0.008\n",
      "Val acc: 0.916\n",
      "Epoch: 6/10 Iteration: 730 Train loss: 0.012\n",
      "Epoch: 6/10 Iteration: 735 Train loss: 0.023\n",
      "Epoch: 6/10 Iteration: 740 Train loss: 0.025\n",
      "Epoch: 6/10 Iteration: 745 Train loss: 0.022\n",
      "Epoch: 6/10 Iteration: 750 Train loss: 0.013\n",
      "Val acc: 0.931\n",
      "Epoch: 6/10 Iteration: 755 Train loss: 0.016\n",
      "Epoch: 6/10 Iteration: 760 Train loss: 0.015\n",
      "Epoch: 6/10 Iteration: 765 Train loss: 0.013\n",
      "Epoch: 6/10 Iteration: 770 Train loss: 0.016\n",
      "Epoch: 6/10 Iteration: 775 Train loss: 0.013\n",
      "Val acc: 0.929\n",
      "Epoch: 6/10 Iteration: 780 Train loss: 0.023\n",
      "Epoch: 6/10 Iteration: 785 Train loss: 0.011\n",
      "Epoch: 6/10 Iteration: 790 Train loss: 0.012\n",
      "Epoch: 6/10 Iteration: 795 Train loss: 0.014\n",
      "Epoch: 6/10 Iteration: 800 Train loss: 0.023\n",
      "Val acc: 0.922\n",
      "Epoch: 6/10 Iteration: 805 Train loss: 0.033\n",
      "Epoch: 6/10 Iteration: 810 Train loss: 0.016\n",
      "Epoch: 6/10 Iteration: 815 Train loss: 0.018\n",
      "Epoch: 6/10 Iteration: 820 Train loss: 0.017\n",
      "Epoch: 6/10 Iteration: 825 Train loss: 0.037\n",
      "Val acc: 0.912\n",
      "Epoch: 6/10 Iteration: 830 Train loss: 0.024\n",
      "Epoch: 6/10 Iteration: 835 Train loss: 0.011\n",
      "Epoch: 6/10 Iteration: 840 Train loss: 0.024\n",
      "Epoch: 7/10 Iteration: 845 Train loss: 0.013\n",
      "Epoch: 7/10 Iteration: 850 Train loss: 0.012\n",
      "Val acc: 0.927\n",
      "Epoch: 7/10 Iteration: 855 Train loss: 0.016\n",
      "Epoch: 7/10 Iteration: 860 Train loss: 0.013\n",
      "Epoch: 7/10 Iteration: 865 Train loss: 0.024\n",
      "Epoch: 7/10 Iteration: 870 Train loss: 0.012\n",
      "Epoch: 7/10 Iteration: 875 Train loss: 0.017\n",
      "Val acc: 0.928\n",
      "Epoch: 7/10 Iteration: 880 Train loss: 0.009\n",
      "Epoch: 7/10 Iteration: 885 Train loss: 0.015\n",
      "Epoch: 7/10 Iteration: 890 Train loss: 0.013\n",
      "Epoch: 7/10 Iteration: 895 Train loss: 0.011\n",
      "Epoch: 7/10 Iteration: 900 Train loss: 0.025\n",
      "Val acc: 0.923\n",
      "Epoch: 7/10 Iteration: 905 Train loss: 0.015\n",
      "Epoch: 7/10 Iteration: 910 Train loss: 0.006\n",
      "Epoch: 7/10 Iteration: 915 Train loss: 0.014\n",
      "Epoch: 7/10 Iteration: 920 Train loss: 0.016\n",
      "Epoch: 7/10 Iteration: 925 Train loss: 0.020\n",
      "Val acc: 0.922\n",
      "Epoch: 7/10 Iteration: 930 Train loss: 0.018\n",
      "Epoch: 7/10 Iteration: 935 Train loss: 0.024\n",
      "Epoch: 7/10 Iteration: 940 Train loss: 0.016\n",
      "Epoch: 7/10 Iteration: 945 Train loss: 0.013\n",
      "Epoch: 7/10 Iteration: 950 Train loss: 0.017\n",
      "Val acc: 0.927\n",
      "Epoch: 7/10 Iteration: 955 Train loss: 0.015\n",
      "Epoch: 7/10 Iteration: 960 Train loss: 0.020\n",
      "Epoch: 8/10 Iteration: 965 Train loss: 0.004\n",
      "Epoch: 8/10 Iteration: 970 Train loss: 0.011\n",
      "Epoch: 8/10 Iteration: 975 Train loss: 0.011\n",
      "Val acc: 0.928\n",
      "Epoch: 8/10 Iteration: 980 Train loss: 0.015\n",
      "Epoch: 8/10 Iteration: 985 Train loss: 0.027\n",
      "Epoch: 8/10 Iteration: 990 Train loss: 0.031\n",
      "Epoch: 8/10 Iteration: 995 Train loss: 0.025\n",
      "Epoch: 8/10 Iteration: 1000 Train loss: 0.018\n",
      "Val acc: 0.924\n",
      "Epoch: 8/10 Iteration: 1005 Train loss: 0.018\n",
      "Epoch: 8/10 Iteration: 1010 Train loss: 0.007\n",
      "Epoch: 8/10 Iteration: 1015 Train loss: 0.016\n",
      "Epoch: 8/10 Iteration: 1020 Train loss: 0.025\n",
      "Epoch: 8/10 Iteration: 1025 Train loss: 0.014\n",
      "Val acc: 0.925\n",
      "Epoch: 8/10 Iteration: 1030 Train loss: 0.006\n",
      "Epoch: 8/10 Iteration: 1035 Train loss: 0.007\n",
      "Epoch: 8/10 Iteration: 1040 Train loss: 0.018\n",
      "Epoch: 8/10 Iteration: 1045 Train loss: 0.014\n",
      "Epoch: 8/10 Iteration: 1050 Train loss: 0.008\n",
      "Val acc: 0.929\n",
      "Epoch: 8/10 Iteration: 1055 Train loss: 0.017\n",
      "Epoch: 8/10 Iteration: 1060 Train loss: 0.013\n",
      "Epoch: 8/10 Iteration: 1065 Train loss: 0.007\n",
      "Epoch: 8/10 Iteration: 1070 Train loss: 0.015\n",
      "Epoch: 8/10 Iteration: 1075 Train loss: 0.006\n",
      "Val acc: 0.928\n",
      "Epoch: 8/10 Iteration: 1080 Train loss: 0.022\n",
      "Epoch: 9/10 Iteration: 1085 Train loss: 0.006\n",
      "Epoch: 9/10 Iteration: 1090 Train loss: 0.012\n",
      "Epoch: 9/10 Iteration: 1095 Train loss: 0.013\n",
      "Epoch: 9/10 Iteration: 1100 Train loss: 0.014\n",
      "Val acc: 0.929\n",
      "Epoch: 9/10 Iteration: 1105 Train loss: 0.012\n",
      "Epoch: 9/10 Iteration: 1110 Train loss: 0.007\n",
      "Epoch: 9/10 Iteration: 1115 Train loss: 0.020\n",
      "Epoch: 9/10 Iteration: 1120 Train loss: 0.029\n",
      "Epoch: 9/10 Iteration: 1125 Train loss: 0.009\n",
      "Val acc: 0.919\n",
      "Epoch: 9/10 Iteration: 1130 Train loss: 0.006\n",
      "Epoch: 9/10 Iteration: 1135 Train loss: 0.019\n",
      "Epoch: 9/10 Iteration: 1140 Train loss: 0.022\n",
      "Epoch: 9/10 Iteration: 1145 Train loss: 0.007\n",
      "Epoch: 9/10 Iteration: 1150 Train loss: 0.009\n",
      "Val acc: 0.927\n",
      "Epoch: 9/10 Iteration: 1155 Train loss: 0.010\n",
      "Epoch: 9/10 Iteration: 1160 Train loss: 0.015\n",
      "Epoch: 9/10 Iteration: 1165 Train loss: 0.011\n",
      "Epoch: 9/10 Iteration: 1170 Train loss: 0.010\n",
      "Epoch: 9/10 Iteration: 1175 Train loss: 0.017\n",
      "Val acc: 0.926\n",
      "Epoch: 9/10 Iteration: 1180 Train loss: 0.009\n",
      "Epoch: 9/10 Iteration: 1185 Train loss: 0.010\n",
      "Epoch: 9/10 Iteration: 1190 Train loss: 0.014\n",
      "Epoch: 9/10 Iteration: 1195 Train loss: 0.012\n",
      "Epoch: 9/10 Iteration: 1200 Train loss: 0.019\n",
      "Val acc: 0.929\n"
     ]
    }
   ],
   "source": [
    "seq_len = 1000\n",
    "features = np.zeros((len(reviews_ints), seq_len), dtype=int)\n",
    "for i, row in enumerate(reviews_ints):\n",
    "    features[i, -len(row):] = np.array(row)[:seq_len]\n",
    "\n",
    "split_frac = 0.95\n",
    "split_idx = int(len(features)*0.8)\n",
    "train_x, val_x = features[:split_idx], features[split_idx:]\n",
    "train_y, val_y = labels[:split_idx], labels[split_idx:]\n",
    "\n",
    "test_idx = int(len(val_x)*0.5)\n",
    "val_x, test_x = val_x[:test_idx], val_x[test_idx:]\n",
    "val_y, test_y = val_y[:test_idx], val_y[test_idx:]\n",
    "\n",
    "print(\"\\t\\t\\tFeature Shapes:\")\n",
    "print(\"Train set: \\t\\t{}\".format(train_x.shape), \n",
    "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
    "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))\n",
    "lstm_size = 256\n",
    "lstm_layers = 1\n",
    "batch_size_ = 500\n",
    "learning_rate = 0.001\n",
    "\n",
    "n_words = len(vocab_to_int) + 1 # Adding 1 because we use 0's for padding, dictionary started at 1\n",
    "\n",
    "# Create the graph object\n",
    "graph = tf.Graph()\n",
    "# Add nodes to the graph\n",
    "with graph.as_default():\n",
    "    inputs_ = tf.placeholder(tf.int32, [None, None], name='inputs')\n",
    "    labels_ = tf.placeholder(tf.int32, [None, None], name='labels')\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    batch_size = tf.placeholder(tf.int32,[] ,name='batch_size')\n",
    "\n",
    "# Size of the embedding vectors (number of units in the embedding layer)\n",
    "embed_size = 500 \n",
    "\n",
    "with graph.as_default():\n",
    "    embedding = tf.Variable(tf.random_uniform((n_words, embed_size), -1, 1))\n",
    "    embed = tf.nn.embedding_lookup(embedding, inputs_)\n",
    "\n",
    "with graph.as_default():\n",
    "    # Your basic LSTM cell\n",
    "    lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "    \n",
    "    # Add dropout to the cell\n",
    "    drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "    \n",
    "    # Stack up multiple LSTM layers, for deep learning\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([drop  for i in range(lstm_layers)])\n",
    "    \n",
    "    # Getting an initial state of all zeros\n",
    "    initial_state = cell.zero_state(batch_size, dtype=tf.float32)\n",
    "\n",
    "with graph.as_default():\n",
    "    outputs, final_state = tf.nn.dynamic_rnn(cell, embed,\n",
    "                                             initial_state=initial_state)\n",
    "with graph.as_default():\n",
    "    #predictions = tf.contrib.layers.fully_connected(outputs[:, -1], 1, activation_fn=tf.sigmoid)\n",
    "    ann= tf.contrib.layers.fully_connected(outputs[:, -1], 256, activation_fn=tf.sigmoid)\n",
    "    predictions = tf.contrib.layers.fully_connected(ann, 1, activation_fn=tf.sigmoid)\n",
    "    cost = tf.losses.mean_squared_error(labels_, predictions)\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "with graph.as_default():\n",
    "    correct_pred = tf.equal(tf.cast(tf.round(predictions), tf.int32), labels_)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "def get_batches(x, y, batch_size=100):\n",
    "    \n",
    "    n_batches = len(x)//batch_size\n",
    "    x, y = x[:n_batches*batch_size], y[:n_batches*batch_size]\n",
    "    for ii in range(0, len(x), batch_size):\n",
    "        yield x[ii:ii+batch_size], y[ii:ii+batch_size]    \n",
    "        \n",
    "        \n",
    "epochs = 10\n",
    "with graph.as_default():\n",
    "    #saver = tf.train.Saver()\n",
    "    saver = tf.train.Saver(var_list=tf.trainable_variables())\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration = 1\n",
    "    for e in range(epochs):\n",
    "        state = sess.run(initial_state,feed_dict={batch_size:batch_size_})\n",
    "        \n",
    "        for ii, (x, y) in enumerate(get_batches(train_x, train_y, batch_size_), 1):\n",
    "            feed = {inputs_: x,\n",
    "                    labels_: y[:, None],\n",
    "                    keep_prob: 0.5,\n",
    "                    initial_state: state,\n",
    "                    batch_size:batch_size_ }\n",
    "            loss, state, _ = sess.run([cost, final_state, optimizer], feed_dict=feed)\n",
    "            \n",
    "            if iteration%5==0:\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {}\".format(iteration),\n",
    "                      \"Train loss: {:.3f}\".format(loss))\n",
    "\n",
    "            if iteration%25==0:\n",
    "                val_acc = []\n",
    "                val_state = sess.run(initial_state,feed_dict={batch_size:batch_size_})\n",
    "                for x, y in get_batches(val_x, val_y, batch_size_):\n",
    "                    feed = {inputs_: x,\n",
    "                            labels_: y[:, None],\n",
    "                            keep_prob: 1,\n",
    "                            initial_state: val_state,\n",
    "                            batch_size:batch_size_}\n",
    "                    batch_acc, val_state = sess.run([accuracy, final_state], feed_dict=feed)\n",
    "                    val_acc.append(batch_acc)\n",
    "                print(\"Val acc: {:.3f}\".format(np.mean(val_acc)))\n",
    "            iteration +=1\n",
    "    saver.save(sess, \"checkpoints/sentiment.ckpt\")\n",
    "    #saver.save(sess, \"sentiment_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_test_reviews=[]\n",
    "for review in test[\"review\"]:\n",
    "    cleaned_test_reviews.append(review_to_words( review ))\n",
    "\n",
    "\n",
    "reviews_test_ints = []\n",
    "for each in cleaned_test_reviews:\n",
    "    reviews_test_ints.append([vocab_to_int[word] for word in each.split()])\n",
    "    \n",
    "non_zero_idx = [ii for ii, review in enumerate(reviews_test_ints) if len(review) != 0]\n",
    "reviews_test_ints = [reviews_test_ints[ii] for ii in non_zero_idx]    \n",
    "\n",
    "seq_len = 1000\n",
    "features_test = np.zeros((len(reviews_test_ints), seq_len), dtype=int)\n",
    "for i, row in enumerate(reviews_test_ints):\n",
    "    features_test[i, -len(row):] = np.array(row)[:seq_len]\n",
    "X_test=features_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 1000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=[]\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('./'))\n",
    "\n",
    "    test_state = sess.run(initial_state,feed_dict={batch_size:batch_size_})\n",
    "    for i in range(0,X_test.shape[0],batch_size_):\n",
    "        x=X_test[i:i+batch_size_]\n",
    "        \n",
    "        feed = {inputs_: x,                \n",
    "                keep_prob: 1,\n",
    "                initial_state: test_state,\n",
    "                batch_size:1  \n",
    "               }\n",
    "        pred = sess.run(predictions, feed_dict=feed)\n",
    "        preds.extend(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments=[1 if p>0.5 else 0 for p in preds ]\n",
    "test_sub=pd.read_csv('/kaggle/input/word2vec-nlp-tutorial/sampleSubmission.csv')\n",
    "test_sub=test_sub.drop('sentiment',axis=1)\n",
    "test_sub['sentiment']=np.array( sentiments)\n",
    "test_sub.to_csv('sampleSubmission06.csv',index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='sampleSubmission06.csv' target='_blank'>sampleSubmission06.csv</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/sampleSubmission06.csv"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(r'sampleSubmission06.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
